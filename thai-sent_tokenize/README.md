# thai-sent_tokenize

ทดลองการตัดประโยคภาษาไทย โดยใช้ Naive Bayes Classifier

**โครงการนี้เป็นการทดสอบ !!!**

วัดผลโดยแบ่ง 10 % ของข้อมูล(โดยการสุ่ม)ที่ใช้ Train มาทดสอบจำนวน 5 ครั้งดังนี้

```
0.8717948717948718
0.8521870286576169
0.8552036199095022
0.8567119155354449
0.861236802413273
```

เฉลี่ยได้ 0.859426847662142 คิดเป็น 85.9426847662142 %

รันบน Python 3 เท่านั้น

ก่อนใช้งานให้ทำการติดตั้ง PyThaiNLP รุ่นทดสอบโดยใช้คำสั่ง

```
pip install --ignore-installed https://github.com/PyThaiNLP/pythainlp/archive/dev.zip
```

และติดตั้ง dill , emoji ด้วยคำสั่ง

```
pip install emoji dill
```

คำอธิบาย

- ไฟล์ run.py เป็นไฟล์สำหรับใช้ตัดประโยค และ ทดสอบ
- ไฟล์ train.py เป็นไฟล์ที่ใช้ train ข้อมูล
- ไฟล์ using.py เป็นไฟล์รันสำหรับตัดประโยค
- ไฟล์ corpus.txt เป็นไฟล์ตัวอย่างประโยคสำหรับใช้ Train ตัวตัดประโยค
- ไฟล์ thai.txt เป็นคลังคำศัพท์
- ใช้  Naive Bayes Classifier ในการ train
- ทำตาม http://www.nltk.org/book/ch06.html#code-classification-based-segmenter

การใช้งาน

โครงการนี้เป็นการทดสอบการตัดประโยคภาษาไทย

- ให้ทำการติดตั้ง PyThaiNLP และ NLTK ก่อน
- รันไฟล์ using.py

ตัวอย่างการใช้งาน

```python
Text : สวัสดีครับเรามาลองตัดประโยคภาษาไทยกัน
sent : สวัสดีครับ/เรามาลองตัดประโยคภาษาไทยกัน
```

พัฒนาโดย นาย วรรณพงษ์  ภัททิยไพบูลย์

นักศึกษาชั้นปีที่ 1

สาขาวิทยาการคอมพิวเตอร์และสารสนเทศ คณะวิทยาศาสตร์ประยุกต์และวิศวกรรมศาสตร์

มหาวิทยาลัยขอนแก่น วิทยาเขตหนองคาย
